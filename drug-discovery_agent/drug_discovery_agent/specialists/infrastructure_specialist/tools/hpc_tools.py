# Copyright 2025 Google LLC
# Licensed under the Apache License, Version 2.0.

"""
HPC Infrastructure Tools.
These are 'Custom Tools' as per the Micro-agent Architecture best practices.
"""

def deploy_hpc_cluster(cluster_name: str, node_count: int = 4, machine_type: str = "c2-standard-60") -> str:
    """
    Deploys a High Performance Computing (HPC) cluster on Google Cloud.
    Use this to provision resources for heavy molecular dynamics or docking simulations.

    Args:
        cluster_name: The name of the cluster (e.g., 'docking-cluster-01').
        node_count: Number of compute nodes (default: 4).
        machine_type: The GCE machine type (default: c2-standard-60 for compute-optimized).

    Returns:
        Status message with the connection command.
    """
    # In production, this would use google-cloud-compute or Terraform.
    print(f"ðŸ‘· [Infrastructure] Deploying HPC Cluster '{cluster_name}' with {node_count} x {machine_type} nodes...")
    
    return (
        f"âœ… SUCCESS: HPC Cluster '{cluster_name}' deployed.\n"
        f"   - Nodes: {node_count}\n"
        f"   - Type: {machine_type}\n"
        f"   - Status: READY\n"
        f"   - Connection: gcloud compute ssh {cluster_name}-master"
    )

def submit_slurm_job(cluster_name: str, job_script: str) -> str:
    """
    Submits a batch job to an existing HPC cluster.

    Args:
        cluster_name: The target cluster.
        job_script: The bash script or command to run (e.g., 'sbatch run_docking.sh').
    """
    print(f"ðŸš€ [Infrastructure] Submitting job to {cluster_name}...")
    return f"Job submitted to {cluster_name}. Job ID: 4921. Status: PENDING."

def check_job_status(job_id: str) -> str:
    """Checks the status of a deployed HPC job."""
    return f"Job {job_id}: COMPLETED. Results available in gs://rsabawi-data/results/{job_id}/"